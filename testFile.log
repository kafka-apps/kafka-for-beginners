20:09:16.666 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

20:09:16.828 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
20:09:16.829 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
20:09:16.829 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674225556826
20:09:17.103 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
20:09:17.146 [main] INFO  org.kafka.learn.MessageProducer - message message1 of key1 sent successfully  for the key : key1 
20:09:17.146 [main] INFO  org.kafka.learn.MessageProducer - published message for the partition : 2 , offset : 4
20:09:17.154 [main] INFO  org.kafka.learn.MessageProducer - message message2 of key1 sent successfully  for the key : key1 
20:09:17.154 [main] INFO  org.kafka.learn.MessageProducer - published message for the partition : 2 , offset : 5
20:09:17.156 [main] INFO  org.kafka.learn.MessageProducer - message message1 of key2 sent successfully  for the key : key2 
20:09:17.156 [main] INFO  org.kafka.learn.MessageProducer - published message for the partition : 2 , offset : 6
20:09:17.194 [main] INFO  org.kafka.learn.MessageProducer - message message1 of key3 sent successfully  for the key : key3 
20:09:17.194 [main] INFO  org.kafka.learn.MessageProducer - published message for the partition : 1 , offset : 8
20:09:17.196 [main] INFO  org.kafka.learn.MessageProducer - message message3 of key1 sent successfully  for the key : key1 
20:09:17.196 [main] INFO  org.kafka.learn.MessageProducer - published message for the partition : 2 , offset : 7
20:09:17.199 [main] INFO  org.kafka.learn.MessageProducer - message message2 of key3 sent successfully  for the key : key3 
20:09:17.199 [main] INFO  org.kafka.learn.MessageProducer - published message for the partition : 1 , offset : 9
20:09:17.201 [main] INFO  org.kafka.learn.MessageProducer - message message2 of key2 sent successfully  for the key : key2 
20:09:17.201 [main] INFO  org.kafka.learn.MessageProducer - published message for the partition : 2 , offset : 8
20:09:17.202 [main] INFO  org.kafka.learn.MessageProducer - message message4 of key2 sent successfully  for the key : key2 
20:09:17.202 [main] INFO  org.kafka.learn.MessageProducer - published message for the partition : 2 , offset : 9
20:09:17.204 [main] INFO  org.kafka.learn.MessageProducer - message message3 of key2 sent successfully  for the key : key2 
20:09:17.204 [main] INFO  org.kafka.learn.MessageProducer - published message for the partition : 2 , offset : 10
20:09:17.230 [main] INFO  org.kafka.learn.MessageProducer - message message1 of key4 sent successfully  for the key : key4 
20:09:17.230 [main] INFO  org.kafka.learn.MessageProducer - published message for the partition : 0 , offset : 1
20:09:17.231 [main] INFO  org.kafka.learn.MessageProducer - message message4 of key4 sent successfully  for the key : key4 
20:09:17.231 [main] INFO  org.kafka.learn.MessageProducer - published message for the partition : 0 , offset : 2
20:09:17.233 [main] INFO  org.kafka.learn.MessageProducer - message message2 of key4 sent successfully  for the key : key4 
20:09:17.233 [main] INFO  org.kafka.learn.MessageProducer - published message for the partition : 0 , offset : 3
12:16:35.399 [main] INFO  o.kafka.launcher.CommandLineLauncher - Selected Option is : 1 
12:16:45.423 [main] INFO  o.kafka.launcher.CommandLineLauncher - Entered message is hey
12:16:45.460 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

12:16:45.596 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
12:16:45.596 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
12:16:45.596 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674283605594
12:16:45.861 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
12:16:45.899 [main] INFO  org.kafka.learn.MessageProducer - message hey sent successfully  for the key : null 
12:16:45.899 [main] INFO  org.kafka.learn.MessageProducer - published message for the partition : 1 , offset : 10
12:16:45.899 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
12:16:52.439 [main] INFO  o.kafka.launcher.CommandLineLauncher - Entered message is 1-hi
12:16:52.440 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

12:16:52.447 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
12:16:52.447 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
12:16:52.447 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674283612447
12:16:52.463 [kafka-producer-network-thread | producer-2] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-2] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
12:16:52.493 [main] INFO  org.kafka.learn.MessageProducer - message hi sent successfully  for the key : 1 
12:16:52.493 [main] INFO  org.kafka.learn.MessageProducer - published message for the partition : 0 , offset : 4
12:16:52.493 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-2] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
12:16:57.449 [main] INFO  o.kafka.launcher.CommandLineLauncher - Entered message is 1-command
12:16:57.450 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

12:16:57.456 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
12:16:57.456 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
12:16:57.456 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674283617456
12:16:57.462 [kafka-producer-network-thread | producer-3] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-3] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
12:16:57.468 [main] INFO  org.kafka.learn.MessageProducer - message command sent successfully  for the key : 1 
12:16:57.468 [main] INFO  org.kafka.learn.MessageProducer - published message for the partition : 0 , offset : 5
12:16:57.468 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-3] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
12:17:02.457 [main] INFO  o.kafka.launcher.CommandLineLauncher - Entered message is 1-launcher
12:17:02.458 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

12:17:02.462 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
12:17:02.463 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
12:17:02.463 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674283622462
12:17:02.468 [kafka-producer-network-thread | producer-4] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-4] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
12:17:02.472 [main] INFO  org.kafka.learn.MessageProducer - message launcher sent successfully  for the key : 1 
12:17:02.472 [main] INFO  org.kafka.learn.MessageProducer - published message for the partition : 0 , offset : 6
12:17:02.473 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-4] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
12:17:10.470 [main] INFO  o.kafka.launcher.CommandLineLauncher - Entered message is 2-sending
12:17:10.471 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

12:17:10.475 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
12:17:10.476 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
12:17:10.476 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674283630475
12:17:10.480 [kafka-producer-network-thread | producer-5] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-5] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
12:17:10.508 [main] INFO  org.kafka.learn.MessageProducer - message sending sent successfully  for the key : 2 
12:17:10.508 [main] INFO  org.kafka.learn.MessageProducer - published message for the partition : 2 , offset : 11
12:17:10.509 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-5] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
12:17:14.477 [main] INFO  o.kafka.launcher.CommandLineLauncher - Entered message is 2-with
12:17:14.478 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

12:17:14.482 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
12:17:14.483 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
12:17:14.483 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674283634482
12:17:14.487 [kafka-producer-network-thread | producer-6] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-6] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
12:17:14.494 [main] INFO  org.kafka.learn.MessageProducer - message with sent successfully  for the key : 2 
12:17:14.494 [main] INFO  org.kafka.learn.MessageProducer - published message for the partition : 2 , offset : 12
12:17:14.494 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-6] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
12:17:18.487 [main] INFO  o.kafka.launcher.CommandLineLauncher - Entered message is 2-another
12:17:18.487 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

12:17:18.492 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
12:17:18.492 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
12:17:18.492 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674283638492
12:17:18.495 [kafka-producer-network-thread | producer-7] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-7] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
12:17:18.500 [main] INFO  org.kafka.learn.MessageProducer - message another sent successfully  for the key : 2 
12:17:18.500 [main] INFO  org.kafka.learn.MessageProducer - published message for the partition : 2 , offset : 13
12:17:18.500 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-7] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
12:17:21.491 [main] INFO  o.kafka.launcher.CommandLineLauncher - Entered message is 2-key
12:17:21.493 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

12:17:21.497 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
12:17:21.498 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
12:17:21.498 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674283641497
12:17:21.502 [kafka-producer-network-thread | producer-8] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-8] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
12:17:21.507 [main] INFO  org.kafka.learn.MessageProducer - message key sent successfully  for the key : 2 
12:17:21.508 [main] INFO  org.kafka.learn.MessageProducer - published message for the partition : 2 , offset : 14
12:17:21.508 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-8] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
12:17:27.506 [main] INFO  o.kafka.launcher.CommandLineLauncher - Entered message is 00
12:17:27.507 [main] INFO  o.kafka.launcher.CommandLineLauncher - Exiting from Option : 1
12:17:32.522 [main] INFO  o.kafka.launcher.CommandLineLauncher - Selected Option is : 3 
12:17:35.528 [main] INFO  o.kafka.launcher.CommandLineLauncher - Selected Option is : 2 
19:31:45.207 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:31:45.377 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:31:45.378 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:31:45.378 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674309705373
19:31:45.638 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
19:31:45.682 [main] INFO  org.kafka.learn.MessageProducer - message sending message2 from api call sent successfully  for the key : null 
19:31:45.683 [main] INFO  org.kafka.learn.MessageProducer - published message for the partition : 0 , offset : 7
19:31:45.683 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
19:32:52.685 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:32:52.812 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:32:52.813 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:32:52.813 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674309772810
19:32:53.103 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
19:32:53.155 [main] INFO  org.kafka.learn.MessageProducer - message message1 of key1 sent successfully  for the key : key1 
19:32:53.155 [main] INFO  org.kafka.learn.MessageProducer - published message for the partition : 2 , offset : 15
19:32:53.155 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
19:32:53.160 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
19:33:24.637 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:33:24.766 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:33:24.767 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:33:24.767 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674309804764
19:33:25.013 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
19:33:25.052 [main] INFO  org.kafka.learn.MessageProducer - message message1 of key1 sent successfully  for the key : key1 
19:33:25.053 [main] INFO  org.kafka.learn.MessageProducer - published message for the partition : 2 , offset : 16
19:33:25.053 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
19:33:25.063 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
19:33:58.151 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:33:58.283 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:33:58.284 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:33:58.284 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674309838280
19:33:58.608 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
19:33:58.641 [main] INFO  org.kafka.learn.MessageProducer - message message1 of key1 sent successfully  for the key : key1 
19:33:58.641 [main] INFO  org.kafka.learn.MessageProducer - published message for the partition : 2 , offset : 17
19:33:58.643 [main] INFO  org.kafka.learn.MessageProducer - message message2 of key1 sent successfully  for the key : key1 
19:33:58.644 [main] INFO  org.kafka.learn.MessageProducer - published message for the partition : 2 , offset : 18
19:33:58.646 [main] INFO  org.kafka.learn.MessageProducer - message message1 of key2 sent successfully  for the key : key2 
19:33:58.646 [main] INFO  org.kafka.learn.MessageProducer - published message for the partition : 2 , offset : 19
19:33:58.663 [main] INFO  org.kafka.learn.MessageProducer - message message1 of key3 sent successfully  for the key : key3 
19:33:58.664 [main] INFO  org.kafka.learn.MessageProducer - published message for the partition : 1 , offset : 11
19:33:58.666 [main] INFO  org.kafka.learn.MessageProducer - message message3 of key1 sent successfully  for the key : key1 
19:33:58.666 [main] INFO  org.kafka.learn.MessageProducer - published message for the partition : 2 , offset : 20
19:33:58.668 [main] INFO  org.kafka.learn.MessageProducer - message message2 of key3 sent successfully  for the key : key3 
19:33:58.668 [main] INFO  org.kafka.learn.MessageProducer - published message for the partition : 1 , offset : 12
19:33:58.670 [main] INFO  org.kafka.learn.MessageProducer - message message2 of key2 sent successfully  for the key : key2 
19:33:58.670 [main] INFO  org.kafka.learn.MessageProducer - published message for the partition : 2 , offset : 21
19:33:58.672 [main] INFO  org.kafka.learn.MessageProducer - message message4 of key2 sent successfully  for the key : key2 
19:33:58.672 [main] INFO  org.kafka.learn.MessageProducer - published message for the partition : 2 , offset : 22
19:33:58.675 [main] INFO  org.kafka.learn.MessageProducer - message message3 of key2 sent successfully  for the key : key2 
19:33:58.675 [main] INFO  org.kafka.learn.MessageProducer - published message for the partition : 2 , offset : 23
19:33:58.680 [main] INFO  org.kafka.learn.MessageProducer - message message1 of key4 sent successfully  for the key : key4 
19:33:58.680 [main] INFO  org.kafka.learn.MessageProducer - published message for the partition : 0 , offset : 8
19:33:58.682 [main] INFO  org.kafka.learn.MessageProducer - message message4 of key4 sent successfully  for the key : key4 
19:33:58.682 [main] INFO  org.kafka.learn.MessageProducer - published message for the partition : 0 , offset : 9
19:33:58.684 [main] INFO  org.kafka.learn.MessageProducer - message message2 of key4 sent successfully  for the key : key4 
19:33:58.684 [main] INFO  org.kafka.learn.MessageProducer - published message for the partition : 0 , offset : 10
19:34:08.549 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:34:08.670 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:34:08.671 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:34:08.672 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674309848669
19:34:08.869 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
19:34:08.893 [main] INFO  org.kafka.learn.MessageProducer - message message1 of key1 sent successfully  for the key : key1 
19:34:08.893 [main] INFO  org.kafka.learn.MessageProducer - published message for the partition : 2 , offset : 24
19:34:08.894 [main] INFO  org.kafka.learn.MessageProducer - message message2 of key1 sent successfully  for the key : key1 
19:34:08.894 [main] INFO  org.kafka.learn.MessageProducer - published message for the partition : 2 , offset : 25
19:34:08.896 [main] INFO  org.kafka.learn.MessageProducer - message message1 of key2 sent successfully  for the key : key2 
19:34:08.896 [main] INFO  org.kafka.learn.MessageProducer - published message for the partition : 2 , offset : 26
19:34:08.900 [main] INFO  org.kafka.learn.MessageProducer - message message1 of key3 sent successfully  for the key : key3 
19:34:08.900 [main] INFO  org.kafka.learn.MessageProducer - published message for the partition : 1 , offset : 13
19:34:08.902 [main] INFO  org.kafka.learn.MessageProducer - message message3 of key1 sent successfully  for the key : key1 
19:34:08.902 [main] INFO  org.kafka.learn.MessageProducer - published message for the partition : 2 , offset : 27
19:34:08.904 [main] INFO  org.kafka.learn.MessageProducer - message message2 of key3 sent successfully  for the key : key3 
19:34:08.905 [main] INFO  org.kafka.learn.MessageProducer - published message for the partition : 1 , offset : 14
19:34:08.906 [main] INFO  org.kafka.learn.MessageProducer - message message2 of key2 sent successfully  for the key : key2 
19:34:08.906 [main] INFO  org.kafka.learn.MessageProducer - published message for the partition : 2 , offset : 28
19:34:08.907 [main] INFO  org.kafka.learn.MessageProducer - message message4 of key2 sent successfully  for the key : key2 
19:34:08.908 [main] INFO  org.kafka.learn.MessageProducer - published message for the partition : 2 , offset : 29
19:34:08.909 [main] INFO  org.kafka.learn.MessageProducer - message message3 of key2 sent successfully  for the key : key2 
19:34:08.909 [main] INFO  org.kafka.learn.MessageProducer - published message for the partition : 2 , offset : 30
19:34:08.913 [main] INFO  org.kafka.learn.MessageProducer - message message1 of key4 sent successfully  for the key : key4 
19:34:08.913 [main] INFO  org.kafka.learn.MessageProducer - published message for the partition : 0 , offset : 11
19:34:08.914 [main] INFO  org.kafka.learn.MessageProducer - message message4 of key4 sent successfully  for the key : key4 
19:34:08.914 [main] INFO  org.kafka.learn.MessageProducer - published message for the partition : 0 , offset : 12
19:34:08.915 [main] INFO  org.kafka.learn.MessageProducer - message message2 of key4 sent successfully  for the key : key4 
19:34:08.916 [main] INFO  org.kafka.learn.MessageProducer - published message for the partition : 0 , offset : 13
19:34:28.694 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:34:28.816 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:34:28.817 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:34:28.817 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674309868815
19:34:28.820 [main] INFO  org.kafka.learn.MessageProducer - holding the main thread to sleep for 3 seconds
19:34:29.134 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
19:34:31.822 [main] INFO  org.kafka.learn.MessageProducer - sleep for 3 seconds completed
19:35:23.559 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:35:23.677 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:35:23.678 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:35:23.678 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674309923674
19:35:23.877 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
19:35:23.894 [main] INFO  org.kafka.learn.MessageProducer - holding the main thread to sleep for 3 seconds
19:35:23.913 [kafka-producer-network-thread | producer-1] INFO  org.kafka.learn.MessageProducer - message message1 of key1 sent successfully for the key key1
19:35:23.914 [kafka-producer-network-thread | producer-1] INFO  org.kafka.learn.MessageProducer - Published message Offset in callback is 31 and partition : 2
19:35:26.895 [main] INFO  org.kafka.learn.MessageProducer - sleep for 3 seconds completed
19:35:52.371 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:35:52.490 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:35:52.491 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:35:52.491 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674309952489
19:35:52.691 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
19:35:52.702 [main] INFO  org.kafka.learn.MessageProducer - holding the main thread to sleep for 3 seconds
19:35:52.714 [kafka-producer-network-thread | producer-1] INFO  org.kafka.learn.MessageProducer - message sending message asynchronously from api call sent successfully for the key null
19:35:52.715 [kafka-producer-network-thread | producer-1] INFO  org.kafka.learn.MessageProducer - Published message Offset in callback is 32 and partition : 2
19:35:55.707 [main] INFO  org.kafka.learn.MessageProducer - sleep for 3 seconds completed
19:36:42.609 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:36:42.726 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:36:42.727 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:36:42.727 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674310002724
19:36:43.013 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
19:36:43.076 [main] INFO  org.kafka.learn.MessageProducer - message sending message2 from api call sent successfully  for the key : null 
19:36:43.077 [main] INFO  org.kafka.learn.MessageProducer - published message for the partition : 2 , offset : 33
19:37:03.595 [main] INFO  o.kafka.launcher.CommandLineLauncher - Selected Option is : 1 
19:37:06.596 [main] INFO  o.kafka.launcher.CommandLineLauncher - Entered message is hi
19:37:06.619 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:37:06.740 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:37:06.741 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:37:06.741 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674310026738
19:37:06.948 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
19:37:06.984 [main] INFO  o.kafka.launcher.CommandLineLauncher - message hi sent successfully  for the key : null 
19:37:06.984 [main] INFO  o.kafka.launcher.CommandLineLauncher - published message for the partition : 2 , offset : 34
19:37:13.606 [main] INFO  o.kafka.launcher.CommandLineLauncher - Entered message is key1-value1
19:37:13.607 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:37:13.615 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:37:13.616 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:37:13.616 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674310033615
19:37:13.622 [kafka-producer-network-thread | producer-2] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-2] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
19:37:13.628 [main] INFO  o.kafka.launcher.CommandLineLauncher - message value1 sent successfully  for the key : key1 
19:37:13.628 [main] INFO  o.kafka.launcher.CommandLineLauncher - published message for the partition : 2 , offset : 35
19:37:20.622 [main] INFO  o.kafka.launcher.CommandLineLauncher - Entered message is key1-value2
19:37:20.622 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:37:20.627 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:37:20.627 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:37:20.627 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674310040627
19:37:20.631 [kafka-producer-network-thread | producer-3] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-3] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
19:37:20.636 [main] INFO  o.kafka.launcher.CommandLineLauncher - message value2 sent successfully  for the key : key1 
19:37:20.636 [main] INFO  o.kafka.launcher.CommandLineLauncher - published message for the partition : 2 , offset : 36
19:37:26.640 [main] INFO  o.kafka.launcher.CommandLineLauncher - Entered message is 00
19:37:26.642 [main] INFO  o.kafka.launcher.CommandLineLauncher - Exiting from Option : 1
19:37:30.648 [main] INFO  o.kafka.launcher.CommandLineLauncher - Selected Option is : 2 
19:39:21.973 [main] INFO  o.k.learn.MessageProducerReplication - Selected Option is : 1 
19:39:27.984 [main] INFO  o.k.learn.MessageProducerReplication - Entered message is hello
19:39:28.012 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:39:28.139 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:39:28.139 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:39:28.139 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674310168136
19:39:28.141 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:39:28.148 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:39:28.148 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:39:28.148 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674310168148
19:39:28.408 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
19:39:28.408 [kafka-producer-network-thread | producer-2] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-2] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
19:39:28.440 [main] INFO  o.k.learn.MessageProducerReplication - message hello sent successfully  for the key : null 
19:39:28.441 [main] INFO  o.k.learn.MessageProducerReplication - published message for the partition : 0 , offset : 0
19:39:28.441 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
19:39:34.002 [main] INFO  o.k.learn.MessageProducerReplication - Entered message is 1-hi
19:39:34.003 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:39:34.009 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:39:34.009 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:39:34.009 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674310174009
19:39:34.010 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:39:34.015 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:39:34.015 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:39:34.015 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674310174014
19:39:34.021 [kafka-producer-network-thread | producer-4] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-4] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
19:39:34.027 [main] INFO  o.k.learn.MessageProducerReplication - message hi sent successfully  for the key : 1 
19:39:34.028 [main] INFO  o.k.learn.MessageProducerReplication - published message for the partition : 0 , offset : 1
19:39:34.028 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-3] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
19:39:38.016 [main] INFO  o.k.learn.MessageProducerReplication - Entered message is 2-hello
19:39:38.017 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:39:38.022 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:39:38.023 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:39:38.023 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674310178022
19:39:38.024 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:39:38.028 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:39:38.028 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:39:38.028 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674310178027
19:39:38.032 [kafka-producer-network-thread | producer-6] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-6] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
19:39:38.037 [main] INFO  o.k.learn.MessageProducerReplication - message hello sent successfully  for the key : 2 
19:39:38.037 [main] INFO  o.k.learn.MessageProducerReplication - published message for the partition : 2 , offset : 0
19:39:38.037 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-5] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
19:39:43.030 [main] INFO  o.k.learn.MessageProducerReplication - Entered message is 1-hi again
19:39:43.031 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:39:43.035 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:39:43.035 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:39:43.035 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674310183035
19:39:43.036 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:39:43.040 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:39:43.040 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:39:43.040 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674310183040
19:39:43.044 [kafka-producer-network-thread | producer-8] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-8] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
19:39:43.048 [main] INFO  o.k.learn.MessageProducerReplication - message hi again sent successfully  for the key : 1 
19:39:43.049 [main] INFO  o.k.learn.MessageProducerReplication - published message for the partition : 0 , offset : 2
19:39:43.049 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-7] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
19:42:11.966 [kafka-producer-network-thread | producer-6] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-6] Connection to node 2 (localhost/127.0.0.1:9094) could not be established. Broker may not be available.
19:43:18.564 [main] INFO  o.k.learn.MessageProducerReplication - Entered message is hello
19:43:18.565 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:43:18.568 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:43:18.568 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:43:18.568 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674310398568
19:43:18.568 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:43:18.570 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:43:18.571 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:43:18.571 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674310398570
19:43:18.572 [kafka-producer-network-thread | producer-10] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-10] Connection to node -3 (localhost/127.0.0.1:9094) could not be established. Broker may not be available.
19:43:18.574 [kafka-producer-network-thread | producer-10] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-10] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
19:43:18.577 [main] INFO  o.k.learn.MessageProducerReplication - message hello sent successfully  for the key : null 
19:43:18.577 [main] INFO  o.k.learn.MessageProducerReplication - published message for the partition : 1 , offset : 0
19:43:18.578 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-9] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
19:44:12.702 [main] INFO  o.k.learn.MessageProducerReplication - Entered message is hi
19:44:12.703 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:44:12.706 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:44:12.707 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:44:12.707 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674310452706
19:44:12.707 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:44:12.709 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:44:12.709 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:44:12.709 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674310452709
19:44:12.712 [kafka-producer-network-thread | producer-12] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-12] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
19:44:12.718 [main] INFO  o.k.learn.MessageProducerReplication - message hi sent successfully  for the key : null 
19:44:12.718 [main] INFO  o.k.learn.MessageProducerReplication - published message for the partition : 2 , offset : 1
19:44:12.718 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-11] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
19:44:38.750 [main] INFO  o.k.learn.MessageProducerReplication - Entered message is hi
19:44:38.751 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:44:38.753 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:44:38.754 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:44:38.754 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674310478753
19:44:38.754 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:44:38.756 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:44:38.756 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:44:38.756 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674310478756
19:44:38.759 [kafka-producer-network-thread | producer-14] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-14] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
19:44:38.763 [main] INFO  o.k.learn.MessageProducerReplication - message hi sent successfully  for the key : null 
19:44:38.763 [main] INFO  o.k.learn.MessageProducerReplication - published message for the partition : 0 , offset : 3
19:44:38.763 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-13] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
19:45:48.050 [main] INFO  o.k.learn.MessageProducerReplication - Selected Option is : 1 
19:45:54.060 [main] INFO  o.k.learn.MessageProducerReplication - Entered message is 1-value1
19:45:54.085 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:45:54.208 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:45:54.209 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:45:54.209 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674310554206
19:45:54.211 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:45:54.218 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:45:54.219 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:45:54.219 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674310554218
19:45:54.498 [kafka-producer-network-thread | producer-2] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-2] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
19:45:54.499 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
19:45:54.543 [main] INFO  o.k.learn.MessageProducerReplication - message value1 sent successfully  for the key : 1 
19:45:54.543 [main] INFO  o.k.learn.MessageProducerReplication - published message for the partition : 0 , offset : 4
19:45:54.543 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
19:47:22.302 [main] INFO  o.k.learn.MessageProducerReplication - Entered message is here
19:47:22.303 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:47:22.308 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:47:22.309 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:47:22.309 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674310642308
19:47:22.309 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:47:22.313 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:47:22.314 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:47:22.314 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674310642313
19:47:22.317 [kafka-producer-network-thread | producer-4] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-4] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
19:47:22.322 [main] INFO  o.k.learn.MessageProducerReplication - message here sent successfully  for the key : null 
19:47:22.322 [main] INFO  o.k.learn.MessageProducerReplication - published message for the partition : 2 , offset : 2
19:47:22.322 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-3] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
19:48:09.393 [main] INFO  o.k.learn.MessageProducerReplication - Entered message is are you still 
19:48:09.393 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:48:09.397 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:48:09.398 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:48:09.398 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674310689397
19:48:09.398 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:48:09.401 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:48:09.401 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:48:09.401 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674310689401
19:48:09.403 [kafka-producer-network-thread | producer-6] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-6] Connection to node -2 (localhost/127.0.0.1:9093) could not be established. Broker may not be available.
19:48:09.406 [kafka-producer-network-thread | producer-6] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-6] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
19:48:09.410 [main] INFO  o.k.learn.MessageProducerReplication - message are you still  sent successfully  for the key : null 
19:48:09.410 [main] INFO  o.k.learn.MessageProducerReplication - published message for the partition : 2 , offset : 3
19:48:09.410 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-5] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
19:48:12.397 [main] INFO  o.k.learn.MessageProducerReplication - Entered message is available
19:48:12.397 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:48:12.401 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:48:12.401 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:48:12.401 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674310692401
19:48:12.402 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:48:12.406 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:48:12.406 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:48:12.406 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674310692406
19:48:12.408 [kafka-producer-network-thread | producer-8] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-8] Connection to node -3 (localhost/127.0.0.1:9094) could not be established. Broker may not be available.
19:48:12.409 [kafka-producer-network-thread | producer-8] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-8] Connection to node -2 (localhost/127.0.0.1:9093) could not be established. Broker may not be available.
19:48:12.412 [kafka-producer-network-thread | producer-8] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-8] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
19:48:12.416 [main] INFO  o.k.learn.MessageProducerReplication - message available sent successfully  for the key : null 
19:48:12.416 [main] INFO  o.k.learn.MessageProducerReplication - published message for the partition : 0 , offset : 5
19:48:12.417 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-7] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
19:48:15.402 [main] INFO  o.k.learn.MessageProducerReplication - Entered message is consuming my 
19:48:15.402 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:48:15.406 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:48:15.406 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:48:15.406 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674310695406
19:48:15.406 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:48:15.409 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:48:15.409 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:48:15.409 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674310695409
19:48:15.411 [kafka-producer-network-thread | producer-10] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-10] Connection to node -3 (localhost/127.0.0.1:9094) could not be established. Broker may not be available.
19:48:15.411 [kafka-producer-network-thread | producer-10] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-10] Connection to node -2 (localhost/127.0.0.1:9093) could not be established. Broker may not be available.
19:48:15.414 [kafka-producer-network-thread | producer-10] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-10] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
19:48:15.418 [main] INFO  o.k.learn.MessageProducerReplication - message consuming my  sent successfully  for the key : null 
19:48:15.418 [main] INFO  o.k.learn.MessageProducerReplication - published message for the partition : 2 , offset : 4
19:48:15.418 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-9] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
19:48:17.405 [main] INFO  o.k.learn.MessageProducerReplication - Entered message is messages
19:48:17.406 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:48:17.409 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:48:17.409 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:48:17.409 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674310697409
19:48:17.410 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:48:17.412 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:48:17.412 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:48:17.412 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674310697412
19:48:17.414 [kafka-producer-network-thread | producer-12] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-12] Connection to node -2 (localhost/127.0.0.1:9093) could not be established. Broker may not be available.
19:48:17.417 [kafka-producer-network-thread | producer-12] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-12] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
19:48:17.422 [main] INFO  o.k.learn.MessageProducerReplication - message messages sent successfully  for the key : null 
19:48:17.422 [main] INFO  o.k.learn.MessageProducerReplication - published message for the partition : 1 , offset : 1
19:48:17.422 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-11] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
19:48:18.409 [main] INFO  o.k.learn.MessageProducerReplication - Entered message is ?
19:48:18.410 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:48:18.413 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:48:18.413 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:48:18.414 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674310698413
19:48:18.414 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:48:18.416 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:48:18.416 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:48:18.416 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674310698416
19:48:18.417 [kafka-producer-network-thread | producer-14] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-14] Connection to node -2 (localhost/127.0.0.1:9093) could not be established. Broker may not be available.
19:48:18.418 [kafka-producer-network-thread | producer-14] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-14] Connection to node -3 (localhost/127.0.0.1:9094) could not be established. Broker may not be available.
19:48:18.420 [kafka-producer-network-thread | producer-14] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-14] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
19:48:18.423 [main] INFO  o.k.learn.MessageProducerReplication - message ? sent successfully  for the key : null 
19:48:18.423 [main] INFO  o.k.learn.MessageProducerReplication - published message for the partition : 1 , offset : 2
19:48:18.423 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-13] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
19:48:56.512 [main] INFO  o.k.learn.MessageProducerReplication - Entered message is there?
19:48:56.513 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:48:56.516 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:48:56.517 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:48:56.517 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674310736516
19:48:56.517 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:48:56.519 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:48:56.520 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:48:56.520 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674310736519
19:48:56.537 [kafka-producer-network-thread | producer-16] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-16] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
19:48:56.540 [main] INFO  o.k.learn.MessageProducerReplication - message there? sent successfully  for the key : null 
19:48:56.541 [main] INFO  o.k.learn.MessageProducerReplication - published message for the partition : 2 , offset : 5
19:48:56.541 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-15] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
19:50:57.808 [main] INFO  o.k.learn.MessageProducerReplication - Entered message is there>
19:50:57.809 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:50:57.811 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:50:57.812 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:50:57.812 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674310857811
19:50:57.812 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:50:57.814 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:50:57.814 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:50:57.814 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674310857814
19:50:57.817 [kafka-producer-network-thread | producer-18] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-18] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
19:50:57.821 [main] INFO  o.k.learn.MessageProducerReplication - message there> sent successfully  for the key : null 
19:50:57.821 [main] INFO  o.k.learn.MessageProducerReplication - published message for the partition : 0 , offset : 6
19:50:57.821 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-17] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
19:51:20.873 [main] INFO  o.k.learn.MessageProducerReplication - Entered message is hi
19:51:20.874 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:51:20.877 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:51:20.877 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:51:20.877 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674310880877
19:51:20.878 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:51:20.880 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:51:20.880 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:51:20.880 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674310880880
19:51:20.883 [kafka-producer-network-thread | producer-20] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-20] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
19:51:20.886 [main] INFO  o.k.learn.MessageProducerReplication - message hi sent successfully  for the key : null 
19:51:20.886 [main] INFO  o.k.learn.MessageProducerReplication - published message for the partition : 2 , offset : 6
19:51:20.886 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-19] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
19:51:50.951 [main] INFO  o.k.learn.MessageProducerReplication - Entered message is hi
19:51:50.953 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:51:50.956 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:51:50.956 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:51:50.956 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674310910956
19:51:50.957 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:51:50.959 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:51:50.959 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:51:50.959 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674310910959
19:51:50.962 [kafka-producer-network-thread | producer-22] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-22] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
19:51:50.965 [main] INFO  o.k.learn.MessageProducerReplication - message hi sent successfully  for the key : null 
19:51:50.965 [main] INFO  o.k.learn.MessageProducerReplication - published message for the partition : 1 , offset : 3
19:51:50.965 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-21] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
19:51:53.959 [main] INFO  o.k.learn.MessageProducerReplication - Entered message is I have
19:51:53.959 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:51:53.961 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:51:53.961 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:51:53.961 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674310913961
19:51:53.961 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:51:53.963 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:51:53.963 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:51:53.963 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674310913963
19:51:53.966 [kafka-producer-network-thread | producer-24] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-24] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
19:51:53.970 [main] INFO  o.k.learn.MessageProducerReplication - message I have sent successfully  for the key : null 
19:51:53.970 [main] INFO  o.k.learn.MessageProducerReplication - published message for the partition : 1 , offset : 4
19:51:53.970 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-23] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
19:51:57.969 [main] INFO  o.k.learn.MessageProducerReplication - Entered message is stopped
19:51:57.970 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:51:57.972 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:51:57.972 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:51:57.972 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674310917972
19:51:57.972 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:51:57.974 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:51:57.974 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:51:57.974 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674310917974
19:51:57.977 [kafka-producer-network-thread | producer-26] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-26] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
19:51:57.980 [main] INFO  o.k.learn.MessageProducerReplication - message stopped sent successfully  for the key : null 
19:51:57.980 [main] INFO  o.k.learn.MessageProducerReplication - published message for the partition : 2 , offset : 7
19:51:57.980 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-25] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
19:52:00.975 [main] INFO  o.k.learn.MessageProducerReplication - Entered message is a replication
19:52:00.976 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:52:00.978 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:52:00.978 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:52:00.978 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674310920978
19:52:00.979 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:52:00.980 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:52:00.980 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:52:00.981 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674310920980
19:52:00.982 [kafka-producer-network-thread | producer-28] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-28] Connection to node -2 (localhost/127.0.0.1:9093) could not be established. Broker may not be available.
19:52:00.984 [kafka-producer-network-thread | producer-28] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-28] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
19:52:00.988 [main] INFO  o.k.learn.MessageProducerReplication - message a replication sent successfully  for the key : null 
19:52:00.988 [main] INFO  o.k.learn.MessageProducerReplication - published message for the partition : 0 , offset : 7
19:52:00.988 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-27] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
19:52:03.983 [main] INFO  o.k.learn.MessageProducerReplication - Entered message is replica
19:52:03.984 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:52:03.986 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:52:03.987 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:52:03.987 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674310923986
19:52:03.987 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:52:03.989 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:52:03.989 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:52:03.989 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674310923989
19:52:03.990 [kafka-producer-network-thread | producer-30] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-30] Connection to node -3 (localhost/127.0.0.1:9094) could not be established. Broker may not be available.
19:52:03.991 [kafka-producer-network-thread | producer-30] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-30] Connection to node -2 (localhost/127.0.0.1:9093) could not be established. Broker may not be available.
19:52:03.993 [kafka-producer-network-thread | producer-30] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-30] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
19:52:03.996 [main] INFO  o.k.learn.MessageProducerReplication - message replica sent successfully  for the key : null 
19:52:03.996 [main] INFO  o.k.learn.MessageProducerReplication - published message for the partition : 2 , offset : 8
19:52:03.996 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-29] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
19:52:57.097 [main] INFO  o.k.learn.MessageProducerReplication - Entered message is hello
19:52:57.099 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:52:57.102 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:52:57.103 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:52:57.103 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674310977102
19:52:57.103 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:52:57.105 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:52:57.105 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:52:57.105 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674310977105
19:52:57.120 [kafka-producer-network-thread | producer-32] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-32] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
19:52:57.123 [main] INFO  o.k.learn.MessageProducerReplication - message hello sent successfully  for the key : null 
19:52:57.123 [main] INFO  o.k.learn.MessageProducerReplication - published message for the partition : 2 , offset : 9
19:52:57.123 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-31] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
19:53:36.203 [main] INFO  o.k.learn.MessageProducerReplication - Entered message is i-am
19:53:36.204 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:53:36.207 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:53:36.207 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:53:36.208 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674311016207
19:53:36.208 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:53:36.210 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:53:36.211 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:53:36.211 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674311016210
19:53:36.228 [kafka-producer-network-thread | producer-34] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-34] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
19:53:36.230 [main] INFO  o.k.learn.MessageProducerReplication - message am sent successfully  for the key : i 
19:53:36.231 [main] INFO  o.k.learn.MessageProducerReplication - published message for the partition : 2 , offset : 10
19:53:36.231 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-33] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
19:53:47.237 [main] INFO  o.k.learn.MessageProducerReplication - Entered message is backi-
19:53:47.237 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:53:47.239 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:53:47.240 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:53:47.240 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674311027239
19:53:47.240 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:53:47.242 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:53:47.242 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:53:47.242 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674311027242
19:53:47.246 [kafka-producer-network-thread | producer-36] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-36] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
19:53:47.250 [main] INFO  o.k.learn.MessageProducerReplication - message backi sent successfully  for the key : null 
19:53:47.250 [main] INFO  o.k.learn.MessageProducerReplication - published message for the partition : 1 , offset : 5
19:53:47.250 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-35] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
19:53:53.258 [main] INFO  o.k.learn.MessageProducerReplication - Entered message is i-back
19:53:53.259 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:53:53.262 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:53:53.262 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:53:53.262 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674311033261
19:53:53.262 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:53:53.264 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:53:53.264 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:53:53.265 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674311033264
19:53:53.269 [kafka-producer-network-thread | producer-38] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-38] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
19:53:53.272 [main] INFO  o.k.learn.MessageProducerReplication - message back sent successfully  for the key : i 
19:53:53.272 [main] INFO  o.k.learn.MessageProducerReplication - published message for the partition : 2 , offset : 11
19:53:53.272 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-37] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
19:54:00.153 [kafka-producer-network-thread | producer-20] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-20] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:00.153 [kafka-producer-network-thread | producer-22] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-22] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:00.154 [kafka-producer-network-thread | producer-26] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-26] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:00.155 [kafka-producer-network-thread | producer-24] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-24] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:00.203 [kafka-producer-network-thread | producer-30] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-30] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:00.205 [kafka-producer-network-thread | producer-28] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-28] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:00.259 [kafka-producer-network-thread | producer-26] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-26] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:00.259 [kafka-producer-network-thread | producer-20] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-20] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:00.259 [kafka-producer-network-thread | producer-22] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-22] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:00.314 [kafka-producer-network-thread | producer-24] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-24] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:00.362 [kafka-producer-network-thread | producer-30] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-30] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:00.364 [kafka-producer-network-thread | producer-28] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-28] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:00.475 [kafka-producer-network-thread | producer-26] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-26] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:00.529 [kafka-producer-network-thread | producer-20] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-20] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:00.529 [kafka-producer-network-thread | producer-22] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-22] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:00.574 [kafka-producer-network-thread | producer-28] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-28] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:00.580 [kafka-producer-network-thread | producer-24] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-24] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:00.625 [kafka-producer-network-thread | producer-30] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-30] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:00.845 [kafka-producer-network-thread | producer-26] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-26] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:00.955 [kafka-producer-network-thread | producer-22] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-22] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:00.955 [kafka-producer-network-thread | producer-20] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-20] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:00.992 [kafka-producer-network-thread | producer-28] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-28] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:01.008 [kafka-producer-network-thread | producer-24] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-24] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:01.046 [kafka-producer-network-thread | producer-30] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-30] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:01.688 [kafka-producer-network-thread | producer-24] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-24] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:01.689 [kafka-producer-network-thread | producer-26] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-26] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:01.730 [kafka-producer-network-thread | producer-28] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-28] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:01.730 [kafka-producer-network-thread | producer-30] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-30] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:01.797 [kafka-producer-network-thread | producer-22] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-22] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:01.848 [kafka-producer-network-thread | producer-20] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-20] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:02.570 [kafka-producer-network-thread | producer-28] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-28] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:02.575 [kafka-producer-network-thread | producer-24] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-24] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:02.630 [kafka-producer-network-thread | producer-30] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-30] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:02.746 [kafka-producer-network-thread | producer-22] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-22] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:02.799 [kafka-producer-network-thread | producer-26] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-26] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:02.893 [kafka-producer-network-thread | producer-20] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-20] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:03.515 [kafka-producer-network-thread | producer-28] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-28] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:03.524 [kafka-producer-network-thread | producer-30] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-30] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:03.689 [kafka-producer-network-thread | producer-26] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-26] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:03.731 [kafka-producer-network-thread | producer-24] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-24] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:03.791 [kafka-producer-network-thread | producer-22] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-22] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:04.104 [kafka-producer-network-thread | producer-20] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-20] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:04.350 [kafka-producer-network-thread | producer-28] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-28] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:04.570 [kafka-producer-network-thread | producer-26] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-26] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:04.582 [kafka-producer-network-thread | producer-30] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-30] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:04.674 [kafka-producer-network-thread | producer-24] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-24] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:04.887 [kafka-producer-network-thread | producer-22] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-22] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:05.254 [kafka-producer-network-thread | producer-20] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-20] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:05.351 [kafka-producer-network-thread | producer-28] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-28] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:05.561 [kafka-producer-network-thread | producer-26] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-26] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:05.569 [kafka-producer-network-thread | producer-24] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-24] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:05.631 [kafka-producer-network-thread | producer-30] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-30] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:05.829 [kafka-producer-network-thread | producer-22] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-22] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:06.251 [kafka-producer-network-thread | producer-28] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-28] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:06.307 [kafka-producer-network-thread | producer-20] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-20] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:06.410 [kafka-producer-network-thread | producer-24] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-24] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:06.527 [kafka-producer-network-thread | producer-30] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-30] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:06.621 [kafka-producer-network-thread | producer-26] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-26] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:06.876 [kafka-producer-network-thread | producer-22] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-22] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:07.146 [kafka-producer-network-thread | producer-20] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-20] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:07.298 [kafka-producer-network-thread | producer-28] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-28] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:07.512 [kafka-producer-network-thread | producer-26] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-26] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:07.617 [kafka-producer-network-thread | producer-24] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-24] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:07.637 [kafka-producer-network-thread | producer-30] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-30] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:07.719 [kafka-producer-network-thread | producer-22] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-22] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:07.983 [kafka-producer-network-thread | producer-20] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-20] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:08.447 [kafka-producer-network-thread | producer-28] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-28] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:08.656 [kafka-producer-network-thread | producer-24] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-24] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:08.709 [kafka-producer-network-thread | producer-26] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-26] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:08.730 [kafka-producer-network-thread | producer-30] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-30] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:08.821 [kafka-producer-network-thread | producer-22] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-22] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:09.131 [kafka-producer-network-thread | producer-20] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-20] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:09.285 [kafka-producer-network-thread | producer-28] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-28] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:09.675 [kafka-producer-network-thread | producer-30] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-30] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:09.760 [kafka-producer-network-thread | producer-22] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-22] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:09.813 [kafka-producer-network-thread | producer-26] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-26] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:09.867 [kafka-producer-network-thread | producer-24] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-24] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:10.282 [kafka-producer-network-thread | producer-28] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-28] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:10.335 [kafka-producer-network-thread | producer-20] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-20] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:10.857 [kafka-producer-network-thread | producer-26] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-26] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:10.857 [kafka-producer-network-thread | producer-22] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-22] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:10.878 [kafka-producer-network-thread | producer-30] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-30] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:10.958 [kafka-producer-network-thread | producer-24] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-24] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:11.179 [kafka-producer-network-thread | producer-20] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-20] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:11.389 [kafka-producer-network-thread | producer-28] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-28] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:11.813 [kafka-producer-network-thread | producer-22] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-22] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:11.968 [kafka-producer-network-thread | producer-26] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-26] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:12.043 [kafka-producer-network-thread | producer-30] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-30] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:12.071 [kafka-producer-network-thread | producer-24] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-24] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:12.235 [kafka-producer-network-thread | producer-20] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-20] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:12.337 [kafka-producer-network-thread | producer-28] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-28] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:12.762 [kafka-producer-network-thread | producer-22] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-22] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:12.921 [kafka-producer-network-thread | producer-24] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-24] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:12.971 [kafka-producer-network-thread | producer-26] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-26] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:13.077 [kafka-producer-network-thread | producer-20] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-20] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:13.143 [kafka-producer-network-thread | producer-30] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-30] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:13.540 [kafka-producer-network-thread | producer-28] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-28] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:13.648 [kafka-producer-network-thread | producer-22] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-22] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:13.966 [kafka-producer-network-thread | producer-26] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-26] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:14.021 [kafka-producer-network-thread | producer-20] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-20] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:14.078 [kafka-producer-network-thread | producer-24] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-24] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:14.285 [kafka-producer-network-thread | producer-30] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-30] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:14.646 [kafka-producer-network-thread | producer-28] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-28] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:14.801 [kafka-producer-network-thread | producer-22] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-22] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:15.066 [kafka-producer-network-thread | producer-26] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-26] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:15.104 [kafka-producer-network-thread | producer-20] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-20] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:15.224 [kafka-producer-network-thread | producer-30] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-30] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:15.291 [kafka-producer-network-thread | producer-24] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-24] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:15.547 [kafka-producer-network-thread | producer-28] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-28] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:15.800 [kafka-producer-network-thread | producer-22] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-22] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:16.000 [kafka-producer-network-thread | producer-20] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-20] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:16.164 [kafka-producer-network-thread | producer-30] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-30] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:16.173 [kafka-producer-network-thread | producer-26] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-26] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:16.437 [kafka-producer-network-thread | producer-24] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-24] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:16.593 [kafka-producer-network-thread | producer-28] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-28] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:16.699 [kafka-producer-network-thread | producer-22] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-22] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:16.858 [kafka-producer-network-thread | producer-20] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-20] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:17.122 [kafka-producer-network-thread | producer-26] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-26] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:17.163 [kafka-producer-network-thread | producer-30] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-30] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:17.532 [kafka-producer-network-thread | producer-24] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-24] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:17.697 [kafka-producer-network-thread | producer-28] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-28] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:17.747 [kafka-producer-network-thread | producer-22] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-22] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:17.760 [kafka-producer-network-thread | producer-20] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-20] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:18.117 [kafka-producer-network-thread | producer-30] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-30] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:18.331 [kafka-producer-network-thread | producer-26] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-26] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:18.537 [kafka-producer-network-thread | producer-24] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-24] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:18.597 [kafka-producer-network-thread | producer-22] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-22] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:18.698 [kafka-producer-network-thread | producer-28] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-28] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:18.763 [kafka-producer-network-thread | producer-20] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-20] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:18.962 [kafka-producer-network-thread | producer-30] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-30] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:19.380 [kafka-producer-network-thread | producer-26] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-26] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:19.539 [kafka-producer-network-thread | producer-22] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-22] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:19.641 [kafka-producer-network-thread | producer-24] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-24] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:19.641 [kafka-producer-network-thread | producer-28] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-28] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:19.849 [kafka-producer-network-thread | producer-30] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-30] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:19.971 [kafka-producer-network-thread | producer-20] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-20] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:20.329 [kafka-producer-network-thread | producer-26] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-26] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:20.488 [kafka-producer-network-thread | producer-28] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-28] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:20.538 [kafka-producer-network-thread | producer-22] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-22] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:20.797 [kafka-producer-network-thread | producer-30] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-30] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:20.806 [kafka-producer-network-thread | producer-24] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-24] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:20.963 [kafka-producer-network-thread | producer-20] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-20] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
19:54:27.350 [main] INFO  o.k.learn.MessageProducerReplication - Entered message is hello
19:54:27.351 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:54:27.352 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:54:27.352 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:54:27.352 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674311067352
19:54:27.353 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:54:27.354 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:54:27.354 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:54:27.354 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674311067354
19:54:27.358 [kafka-producer-network-thread | producer-40] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-40] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
19:54:27.369 [main] INFO  o.k.learn.MessageProducerReplication - message hello sent successfully  for the key : null 
19:54:27.370 [main] INFO  o.k.learn.MessageProducerReplication - published message for the partition : 0 , offset : 8
19:54:27.370 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-39] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
19:59:01.451 [main] INFO  o.k.learn.MessageProducerReplication - Selected Option is : 1 
19:59:06.464 [main] INFO  o.k.learn.MessageProducerReplication - Entered message is 1-value1
19:59:06.489 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:59:06.618 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:59:06.618 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:59:06.618 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674311346616
19:59:06.620 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:59:06.627 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:59:06.627 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:59:06.627 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674311346627
19:59:06.863 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
19:59:06.863 [kafka-producer-network-thread | producer-2] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-2] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
19:59:06.926 [main] INFO  o.k.learn.MessageProducerReplication - message value1 sent successfully  for the key : 1 
19:59:06.926 [main] INFO  o.k.learn.MessageProducerReplication - published message for the partition : 0 , offset : 9
19:59:06.926 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
19:59:17.496 [main] INFO  o.k.learn.MessageProducerReplication - Entered message is 2-value2
19:59:17.497 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:59:17.503 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:59:17.503 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:59:17.503 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674311357503
19:59:17.504 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:59:17.509 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:59:17.509 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:59:17.509 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674311357508
19:59:17.514 [kafka-producer-network-thread | producer-4] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-4] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
19:59:17.537 [main] INFO  o.k.learn.MessageProducerReplication - message value2 sent successfully  for the key : 2 
19:59:17.537 [main] INFO  o.k.learn.MessageProducerReplication - published message for the partition : 2 , offset : 12
19:59:17.538 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-3] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
19:59:25.519 [main] INFO  o.k.learn.MessageProducerReplication - Entered message is value2
19:59:25.520 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:59:25.524 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:59:25.524 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:59:25.525 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674311365524
19:59:25.525 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

19:59:25.528 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
19:59:25.528 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
19:59:25.528 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674311365528
19:59:25.532 [kafka-producer-network-thread | producer-6] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-6] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
19:59:25.539 [main] INFO  o.k.learn.MessageProducerReplication - message value2 sent successfully  for the key : null 
19:59:25.539 [main] INFO  o.k.learn.MessageProducerReplication - published message for the partition : 2 , offset : 13
19:59:25.539 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-5] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
20:00:11.625 [main] INFO  o.k.learn.MessageProducerReplication - Entered message is 3-value3
20:00:11.626 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

20:00:11.630 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
20:00:11.631 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
20:00:11.631 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674311411630
20:00:11.631 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

20:00:11.635 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
20:00:11.635 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
20:00:11.635 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674311411635
20:00:11.650 [kafka-producer-network-thread | producer-8] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-8] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
20:00:11.664 [main] INFO  o.k.learn.MessageProducerReplication - message value3 sent successfully  for the key : 3 
20:00:11.664 [main] INFO  o.k.learn.MessageProducerReplication - published message for the partition : 2 , offset : 14
20:00:11.665 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-7] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
20:00:28.671 [main] INFO  o.k.learn.MessageProducerReplication - Entered message is 0-value0
20:00:28.672 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

20:00:28.675 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
20:00:28.675 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
20:00:28.675 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674311428675
20:00:28.676 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

20:00:28.678 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
20:00:28.678 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
20:00:28.678 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674311428678
20:00:28.682 [kafka-producer-network-thread | producer-10] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-10] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
20:00:28.688 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 3 on topic-partition test-topic-api-1-replication-2, retrying (2147483646 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:28.777 [kafka-producer-network-thread | producer-9] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-9] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
20:00:28.794 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 4 on topic-partition test-topic-api-1-replication-2, retrying (2147483645 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:28.899 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 5 on topic-partition test-topic-api-1-replication-2, retrying (2147483644 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:29.006 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 6 on topic-partition test-topic-api-1-replication-2, retrying (2147483643 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:29.111 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 7 on topic-partition test-topic-api-1-replication-2, retrying (2147483642 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:29.216 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 8 on topic-partition test-topic-api-1-replication-2, retrying (2147483641 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:29.320 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 9 on topic-partition test-topic-api-1-replication-2, retrying (2147483640 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:29.423 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 10 on topic-partition test-topic-api-1-replication-2, retrying (2147483639 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:29.524 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 11 on topic-partition test-topic-api-1-replication-2, retrying (2147483638 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:29.627 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 12 on topic-partition test-topic-api-1-replication-2, retrying (2147483637 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:29.734 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 13 on topic-partition test-topic-api-1-replication-2, retrying (2147483636 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:29.839 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 14 on topic-partition test-topic-api-1-replication-2, retrying (2147483635 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:29.941 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 15 on topic-partition test-topic-api-1-replication-2, retrying (2147483634 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:30.043 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 16 on topic-partition test-topic-api-1-replication-2, retrying (2147483633 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:30.147 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 17 on topic-partition test-topic-api-1-replication-2, retrying (2147483632 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:30.250 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 18 on topic-partition test-topic-api-1-replication-2, retrying (2147483631 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:30.356 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 19 on topic-partition test-topic-api-1-replication-2, retrying (2147483630 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:30.461 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 20 on topic-partition test-topic-api-1-replication-2, retrying (2147483629 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:30.566 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 21 on topic-partition test-topic-api-1-replication-2, retrying (2147483628 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:30.667 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 22 on topic-partition test-topic-api-1-replication-2, retrying (2147483627 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:30.770 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 23 on topic-partition test-topic-api-1-replication-2, retrying (2147483626 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:30.874 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 24 on topic-partition test-topic-api-1-replication-2, retrying (2147483625 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:30.979 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 25 on topic-partition test-topic-api-1-replication-2, retrying (2147483624 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:31.082 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 26 on topic-partition test-topic-api-1-replication-2, retrying (2147483623 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:31.187 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 27 on topic-partition test-topic-api-1-replication-2, retrying (2147483622 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:31.291 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 28 on topic-partition test-topic-api-1-replication-2, retrying (2147483621 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:31.396 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 29 on topic-partition test-topic-api-1-replication-2, retrying (2147483620 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:31.502 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 30 on topic-partition test-topic-api-1-replication-2, retrying (2147483619 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:31.604 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 31 on topic-partition test-topic-api-1-replication-2, retrying (2147483618 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:31.708 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 32 on topic-partition test-topic-api-1-replication-2, retrying (2147483617 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:31.814 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 33 on topic-partition test-topic-api-1-replication-2, retrying (2147483616 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:31.919 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 34 on topic-partition test-topic-api-1-replication-2, retrying (2147483615 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:32.022 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 35 on topic-partition test-topic-api-1-replication-2, retrying (2147483614 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:32.126 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 36 on topic-partition test-topic-api-1-replication-2, retrying (2147483613 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:32.234 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 37 on topic-partition test-topic-api-1-replication-2, retrying (2147483612 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:32.338 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 38 on topic-partition test-topic-api-1-replication-2, retrying (2147483611 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:32.440 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 39 on topic-partition test-topic-api-1-replication-2, retrying (2147483610 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:32.544 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 40 on topic-partition test-topic-api-1-replication-2, retrying (2147483609 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:32.646 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 41 on topic-partition test-topic-api-1-replication-2, retrying (2147483608 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:32.752 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 42 on topic-partition test-topic-api-1-replication-2, retrying (2147483607 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:32.857 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 43 on topic-partition test-topic-api-1-replication-2, retrying (2147483606 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:32.964 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 44 on topic-partition test-topic-api-1-replication-2, retrying (2147483605 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:33.066 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 45 on topic-partition test-topic-api-1-replication-2, retrying (2147483604 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:33.174 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 46 on topic-partition test-topic-api-1-replication-2, retrying (2147483603 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:33.280 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 47 on topic-partition test-topic-api-1-replication-2, retrying (2147483602 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:33.386 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 48 on topic-partition test-topic-api-1-replication-2, retrying (2147483601 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:33.489 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 49 on topic-partition test-topic-api-1-replication-2, retrying (2147483600 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:33.593 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 50 on topic-partition test-topic-api-1-replication-2, retrying (2147483599 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:33.695 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 51 on topic-partition test-topic-api-1-replication-2, retrying (2147483598 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:33.797 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 52 on topic-partition test-topic-api-1-replication-2, retrying (2147483597 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:33.900 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 53 on topic-partition test-topic-api-1-replication-2, retrying (2147483596 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:34.004 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 54 on topic-partition test-topic-api-1-replication-2, retrying (2147483595 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:34.108 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 55 on topic-partition test-topic-api-1-replication-2, retrying (2147483594 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:34.213 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 56 on topic-partition test-topic-api-1-replication-2, retrying (2147483593 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:34.315 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 57 on topic-partition test-topic-api-1-replication-2, retrying (2147483592 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:34.418 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 58 on topic-partition test-topic-api-1-replication-2, retrying (2147483591 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:34.523 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 59 on topic-partition test-topic-api-1-replication-2, retrying (2147483590 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:34.632 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 60 on topic-partition test-topic-api-1-replication-2, retrying (2147483589 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:34.737 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 61 on topic-partition test-topic-api-1-replication-2, retrying (2147483588 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:34.839 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 62 on topic-partition test-topic-api-1-replication-2, retrying (2147483587 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:34.944 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 63 on topic-partition test-topic-api-1-replication-2, retrying (2147483586 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:35.050 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 64 on topic-partition test-topic-api-1-replication-2, retrying (2147483585 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:35.153 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 65 on topic-partition test-topic-api-1-replication-2, retrying (2147483584 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:35.254 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 66 on topic-partition test-topic-api-1-replication-2, retrying (2147483583 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:35.356 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 67 on topic-partition test-topic-api-1-replication-2, retrying (2147483582 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:35.459 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 68 on topic-partition test-topic-api-1-replication-2, retrying (2147483581 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:35.563 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 69 on topic-partition test-topic-api-1-replication-2, retrying (2147483580 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:35.666 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 70 on topic-partition test-topic-api-1-replication-2, retrying (2147483579 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:35.770 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 71 on topic-partition test-topic-api-1-replication-2, retrying (2147483578 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:35.872 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 72 on topic-partition test-topic-api-1-replication-2, retrying (2147483577 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:35.978 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 73 on topic-partition test-topic-api-1-replication-2, retrying (2147483576 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:36.082 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 74 on topic-partition test-topic-api-1-replication-2, retrying (2147483575 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:36.184 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 75 on topic-partition test-topic-api-1-replication-2, retrying (2147483574 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:36.289 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 76 on topic-partition test-topic-api-1-replication-2, retrying (2147483573 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:36.391 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 77 on topic-partition test-topic-api-1-replication-2, retrying (2147483572 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:36.496 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 78 on topic-partition test-topic-api-1-replication-2, retrying (2147483571 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:36.600 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 79 on topic-partition test-topic-api-1-replication-2, retrying (2147483570 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:36.705 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 80 on topic-partition test-topic-api-1-replication-2, retrying (2147483569 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:36.811 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 81 on topic-partition test-topic-api-1-replication-2, retrying (2147483568 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:36.916 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 82 on topic-partition test-topic-api-1-replication-2, retrying (2147483567 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:37.022 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 83 on topic-partition test-topic-api-1-replication-2, retrying (2147483566 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:37.128 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 84 on topic-partition test-topic-api-1-replication-2, retrying (2147483565 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:37.232 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 85 on topic-partition test-topic-api-1-replication-2, retrying (2147483564 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:37.334 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 86 on topic-partition test-topic-api-1-replication-2, retrying (2147483563 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:37.438 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 87 on topic-partition test-topic-api-1-replication-2, retrying (2147483562 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:37.542 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 88 on topic-partition test-topic-api-1-replication-2, retrying (2147483561 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:37.647 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 89 on topic-partition test-topic-api-1-replication-2, retrying (2147483560 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:37.754 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 90 on topic-partition test-topic-api-1-replication-2, retrying (2147483559 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:37.856 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 91 on topic-partition test-topic-api-1-replication-2, retrying (2147483558 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:37.958 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 92 on topic-partition test-topic-api-1-replication-2, retrying (2147483557 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:38.063 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 93 on topic-partition test-topic-api-1-replication-2, retrying (2147483556 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:38.165 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 94 on topic-partition test-topic-api-1-replication-2, retrying (2147483555 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:38.269 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 95 on topic-partition test-topic-api-1-replication-2, retrying (2147483554 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:38.371 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 96 on topic-partition test-topic-api-1-replication-2, retrying (2147483553 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:38.476 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 97 on topic-partition test-topic-api-1-replication-2, retrying (2147483552 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:38.582 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 98 on topic-partition test-topic-api-1-replication-2, retrying (2147483551 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:38.687 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 99 on topic-partition test-topic-api-1-replication-2, retrying (2147483550 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:38.791 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 100 on topic-partition test-topic-api-1-replication-2, retrying (2147483549 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:38.893 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 101 on topic-partition test-topic-api-1-replication-2, retrying (2147483548 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:38.997 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 102 on topic-partition test-topic-api-1-replication-2, retrying (2147483547 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:39.100 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 103 on topic-partition test-topic-api-1-replication-2, retrying (2147483546 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:39.206 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 104 on topic-partition test-topic-api-1-replication-2, retrying (2147483545 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:39.307 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 105 on topic-partition test-topic-api-1-replication-2, retrying (2147483544 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:39.413 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 106 on topic-partition test-topic-api-1-replication-2, retrying (2147483543 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:39.518 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 107 on topic-partition test-topic-api-1-replication-2, retrying (2147483542 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:39.622 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 108 on topic-partition test-topic-api-1-replication-2, retrying (2147483541 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:39.726 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 109 on topic-partition test-topic-api-1-replication-2, retrying (2147483540 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:39.832 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 110 on topic-partition test-topic-api-1-replication-2, retrying (2147483539 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:39.938 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 111 on topic-partition test-topic-api-1-replication-2, retrying (2147483538 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:40.044 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 112 on topic-partition test-topic-api-1-replication-2, retrying (2147483537 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:40.148 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 113 on topic-partition test-topic-api-1-replication-2, retrying (2147483536 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:40.254 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 114 on topic-partition test-topic-api-1-replication-2, retrying (2147483535 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:40.360 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 115 on topic-partition test-topic-api-1-replication-2, retrying (2147483534 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:40.464 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 116 on topic-partition test-topic-api-1-replication-2, retrying (2147483533 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:40.565 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 117 on topic-partition test-topic-api-1-replication-2, retrying (2147483532 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:40.671 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 118 on topic-partition test-topic-api-1-replication-2, retrying (2147483531 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:40.776 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 119 on topic-partition test-topic-api-1-replication-2, retrying (2147483530 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:40.881 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 120 on topic-partition test-topic-api-1-replication-2, retrying (2147483529 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:40.985 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 121 on topic-partition test-topic-api-1-replication-2, retrying (2147483528 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:41.088 [kafka-producer-network-thread | producer-10] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-10] Got error produce response with correlation id 122 on topic-partition test-topic-api-1-replication-2, retrying (2147483527 attempts left). Error: NOT_ENOUGH_REPLICAS
20:00:41.205 [main] INFO  o.k.learn.MessageProducerReplication - message value0 sent successfully  for the key : 0 
20:00:41.205 [main] INFO  o.k.learn.MessageProducerReplication - published message for the partition : 2 , offset : 15
20:00:41.205 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-9] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
20:00:49.730 [main] INFO  o.k.learn.MessageProducerReplication - Entered message is 0-value0
20:00:49.731 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

20:00:49.733 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
20:00:49.733 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
20:00:49.733 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674311449733
20:00:49.734 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

20:00:49.736 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
20:00:49.736 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
20:00:49.736 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674311449736
20:00:49.753 [kafka-producer-network-thread | producer-12] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-12] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
20:00:49.759 [main] INFO  o.k.learn.MessageProducerReplication - message value0 sent successfully  for the key : 0 
20:00:49.760 [main] INFO  o.k.learn.MessageProducerReplication - published message for the partition : 2 , offset : 16
20:00:49.760 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-11] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
20:01:54.973 [main] INFO  o.k.learn.MessageProducerReplication - Selected Option is : 1 
20:01:57.977 [main] INFO  o.k.learn.MessageProducerReplication - Entered message is trying
20:01:57.999 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

20:01:58.125 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
20:01:58.125 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
20:01:58.125 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674311518123
20:01:58.127 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 3000
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

20:01:58.134 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
20:01:58.134 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
20:01:58.134 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674311518134
20:01:58.390 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
20:01:58.390 [kafka-producer-network-thread | producer-2] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-2] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
20:01:58.416 [main] INFO  o.k.learn.MessageProducerReplication - message trying sent successfully  for the key : null 
20:01:58.416 [main] INFO  o.k.learn.MessageProducerReplication - published message for the partition : 2 , offset : 17
20:01:58.416 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
20:02:11.010 [main] INFO  o.k.learn.MessageProducerReplication - Entered message is to
20:02:11.012 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

20:02:11.018 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
20:02:11.018 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
20:02:11.018 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674311531017
20:02:11.018 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 3000
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

20:02:11.023 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
20:02:11.024 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
20:02:11.024 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674311531023
20:02:11.026 [kafka-producer-network-thread | producer-4] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-4] Connection to node -2 (localhost/127.0.0.1:9093) could not be established. Broker may not be available.
20:02:11.030 [kafka-producer-network-thread | producer-4] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-4] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
20:02:11.044 [main] INFO  o.k.learn.MessageProducerReplication - message to sent successfully  for the key : null 
20:02:11.044 [main] INFO  o.k.learn.MessageProducerReplication - published message for the partition : 1 , offset : 6
20:02:11.044 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-3] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
20:02:21.045 [main] INFO  o.k.learn.MessageProducerReplication - Entered message is send
20:02:21.046 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

20:02:21.049 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
20:02:21.049 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
20:02:21.049 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674311541049
20:02:21.050 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 3000
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

20:02:21.052 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
20:02:21.053 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
20:02:21.053 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674311541052
20:02:21.054 [kafka-producer-network-thread | producer-6] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-6] Connection to node -3 (localhost/127.0.0.1:9094) could not be established. Broker may not be available.
20:02:21.055 [kafka-producer-network-thread | producer-6] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-6] Connection to node -2 (localhost/127.0.0.1:9093) could not be established. Broker may not be available.
20:02:21.058 [kafka-producer-network-thread | producer-6] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-6] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
20:02:21.061 [kafka-producer-network-thread | producer-6] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-6] Got error produce response with correlation id 3 on topic-partition test-topic-api-1-replication-1, retrying (9 attempts left). Error: NOT_ENOUGH_REPLICAS
20:02:21.152 [kafka-producer-network-thread | producer-5] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-5] Connection to node -2 (localhost/127.0.0.1:9093) could not be established. Broker may not be available.
20:02:21.153 [kafka-producer-network-thread | producer-5] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-5] Connection to node -3 (localhost/127.0.0.1:9094) could not be established. Broker may not be available.
20:02:21.156 [kafka-producer-network-thread | producer-5] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-5] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
20:02:21.165 [kafka-producer-network-thread | producer-6] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-6] Got error produce response with correlation id 4 on topic-partition test-topic-api-1-replication-1, retrying (8 attempts left). Error: NOT_ENOUGH_REPLICAS
20:02:21.271 [kafka-producer-network-thread | producer-6] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-6] Got error produce response with correlation id 5 on topic-partition test-topic-api-1-replication-1, retrying (7 attempts left). Error: NOT_ENOUGH_REPLICAS
20:02:21.377 [kafka-producer-network-thread | producer-6] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-6] Got error produce response with correlation id 6 on topic-partition test-topic-api-1-replication-1, retrying (6 attempts left). Error: NOT_ENOUGH_REPLICAS
20:02:21.481 [kafka-producer-network-thread | producer-6] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-6] Got error produce response with correlation id 7 on topic-partition test-topic-api-1-replication-1, retrying (5 attempts left). Error: NOT_ENOUGH_REPLICAS
20:02:21.587 [kafka-producer-network-thread | producer-6] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-6] Got error produce response with correlation id 8 on topic-partition test-topic-api-1-replication-1, retrying (4 attempts left). Error: NOT_ENOUGH_REPLICAS
20:02:21.692 [kafka-producer-network-thread | producer-6] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-6] Got error produce response with correlation id 9 on topic-partition test-topic-api-1-replication-1, retrying (3 attempts left). Error: NOT_ENOUGH_REPLICAS
20:02:21.799 [kafka-producer-network-thread | producer-6] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-6] Got error produce response with correlation id 10 on topic-partition test-topic-api-1-replication-1, retrying (2 attempts left). Error: NOT_ENOUGH_REPLICAS
20:02:21.904 [kafka-producer-network-thread | producer-6] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-6] Got error produce response with correlation id 11 on topic-partition test-topic-api-1-replication-1, retrying (1 attempts left). Error: NOT_ENOUGH_REPLICAS
20:02:22.010 [kafka-producer-network-thread | producer-6] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-6] Got error produce response with correlation id 12 on topic-partition test-topic-api-1-replication-1, retrying (0 attempts left). Error: NOT_ENOUGH_REPLICAS
20:02:22.116 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-5] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
20:02:59.681 [main] INFO  o.k.learn.MessageProducerReplication - Selected Option is : 1 
20:03:04.689 [main] INFO  o.k.learn.MessageProducerReplication - Entered message is sending
20:03:04.712 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

20:03:04.834 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
20:03:04.834 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
20:03:04.834 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674311584831
20:03:04.836 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 3000
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

20:03:04.843 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
20:03:04.844 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
20:03:04.844 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674311584843
20:03:04.910 [kafka-producer-network-thread | producer-1] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Connection to node -2 (localhost/127.0.0.1:9093) could not be established. Broker may not be available.
20:03:05.081 [kafka-producer-network-thread | producer-1] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
20:03:05.091 [kafka-producer-network-thread | producer-2] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-2] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
20:03:05.129 [main] INFO  o.k.learn.MessageProducerReplication - message sending sent successfully  for the key : null 
20:03:05.129 [main] INFO  o.k.learn.MessageProducerReplication - published message for the partition : 1 , offset : 7
20:03:05.129 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
20:03:11.711 [main] INFO  o.k.learn.MessageProducerReplication - Entered message is message
20:03:11.712 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

20:03:11.717 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
20:03:11.717 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
20:03:11.717 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674311591717
20:03:11.718 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 3000
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

20:03:11.722 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
20:03:11.722 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
20:03:11.722 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674311591721
20:03:11.723 [kafka-producer-network-thread | producer-4] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-4] Connection to node -3 (localhost/127.0.0.1:9094) could not be established. Broker may not be available.
20:03:11.726 [kafka-producer-network-thread | producer-4] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-4] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
20:03:11.729 [kafka-producer-network-thread | producer-4] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-4] Got error produce response with correlation id 3 on topic-partition test-topic-api-1-replication-2, retrying (9 attempts left). Error: NOT_ENOUGH_REPLICAS
20:03:11.815 [kafka-producer-network-thread | producer-3] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-3] Connection to node -2 (localhost/127.0.0.1:9093) could not be established. Broker may not be available.
20:03:11.818 [kafka-producer-network-thread | producer-3] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-3] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
20:03:14.732 [kafka-producer-network-thread | producer-4] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-4] Got error produce response with correlation id 4 on topic-partition test-topic-api-1-replication-2, retrying (8 attempts left). Error: NOT_ENOUGH_REPLICAS
20:03:17.735 [kafka-producer-network-thread | producer-4] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-4] Got error produce response with correlation id 5 on topic-partition test-topic-api-1-replication-2, retrying (7 attempts left). Error: NOT_ENOUGH_REPLICAS
20:03:20.741 [kafka-producer-network-thread | producer-4] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-4] Got error produce response with correlation id 6 on topic-partition test-topic-api-1-replication-2, retrying (6 attempts left). Error: NOT_ENOUGH_REPLICAS
20:03:23.746 [kafka-producer-network-thread | producer-4] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-4] Got error produce response with correlation id 7 on topic-partition test-topic-api-1-replication-2, retrying (5 attempts left). Error: NOT_ENOUGH_REPLICAS
20:03:26.750 [kafka-producer-network-thread | producer-4] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-4] Got error produce response with correlation id 8 on topic-partition test-topic-api-1-replication-2, retrying (4 attempts left). Error: NOT_ENOUGH_REPLICAS
20:03:29.755 [kafka-producer-network-thread | producer-4] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-4] Got error produce response with correlation id 9 on topic-partition test-topic-api-1-replication-2, retrying (3 attempts left). Error: NOT_ENOUGH_REPLICAS
20:03:32.760 [kafka-producer-network-thread | producer-4] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-4] Got error produce response with correlation id 10 on topic-partition test-topic-api-1-replication-2, retrying (2 attempts left). Error: NOT_ENOUGH_REPLICAS
20:03:35.779 [main] INFO  o.k.learn.MessageProducerReplication - message message sent successfully  for the key : null 
20:03:35.779 [main] INFO  o.k.learn.MessageProducerReplication - published message for the partition : 2 , offset : 18
20:03:35.779 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-3] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
20:03:54.823 [main] INFO  o.k.learn.MessageProducerReplication - Entered message is again
20:03:54.824 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

20:03:54.828 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
20:03:54.829 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
20:03:54.829 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674311634828
20:03:54.829 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 3000
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

20:03:54.832 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
20:03:54.832 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
20:03:54.832 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674311634832
20:03:54.850 [kafka-producer-network-thread | producer-6] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-6] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
20:03:54.855 [main] INFO  o.k.learn.MessageProducerReplication - message again sent successfully  for the key : null 
20:03:54.855 [main] INFO  o.k.learn.MessageProducerReplication - published message for the partition : 2 , offset : 19
20:03:54.855 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-5] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
20:03:59.843 [main] INFO  o.k.learn.MessageProducerReplication - Entered message is keep
20:03:59.844 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

20:03:59.846 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
20:03:59.847 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
20:03:59.847 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674311639846
20:03:59.847 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 3000
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

20:03:59.850 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
20:03:59.850 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
20:03:59.850 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674311639850
20:03:59.854 [kafka-producer-network-thread | producer-8] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-8] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
20:03:59.869 [main] INFO  o.k.learn.MessageProducerReplication - message keep sent successfully  for the key : null 
20:03:59.869 [main] INFO  o.k.learn.MessageProducerReplication - published message for the partition : 1 , offset : 8
20:03:59.870 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-7] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
20:04:01.850 [main] INFO  o.k.learn.MessageProducerReplication - Entered message is going
20:04:01.850 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

20:04:01.854 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
20:04:01.854 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
20:04:01.854 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674311641854
20:04:01.855 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 3000
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

20:04:01.857 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
20:04:01.858 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
20:04:01.858 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674311641857
20:04:01.860 [kafka-producer-network-thread | producer-10] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-10] Connection to node -3 (localhost/127.0.0.1:9094) could not be established. Broker may not be available.
20:04:01.865 [kafka-producer-network-thread | producer-10] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-10] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
20:04:01.870 [main] INFO  o.k.learn.MessageProducerReplication - message going sent successfully  for the key : null 
20:04:01.871 [main] INFO  o.k.learn.MessageProducerReplication - published message for the partition : 1 , offset : 9
20:04:01.871 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-9] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
20:04:03.857 [main] INFO  o.k.learn.MessageProducerReplication - Entered message is good
20:04:03.858 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

20:04:03.861 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
20:04:03.861 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
20:04:03.861 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674311643861
20:04:03.862 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 3000
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

20:04:03.864 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
20:04:03.864 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
20:04:03.864 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674311643864
20:04:03.865 [kafka-producer-network-thread | producer-12] WARN  o.apache.kafka.clients.NetworkClient - [Producer clientId=producer-12] Connection to node -3 (localhost/127.0.0.1:9094) could not be established. Broker may not be available.
20:04:03.870 [kafka-producer-network-thread | producer-12] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-12] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
20:04:03.876 [main] INFO  o.k.learn.MessageProducerReplication - message good sent successfully  for the key : null 
20:04:03.876 [main] INFO  o.k.learn.MessageProducerReplication - published message for the partition : 1 , offset : 10
20:04:03.876 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-11] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
20:06:48.370 [main] INFO  o.k.learn.MessageProducerReplication - Entered message is hi
20:06:48.372 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

20:06:48.376 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
20:06:48.376 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
20:06:48.376 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674311808376
20:06:48.377 [main] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092, localhost:9093, localhost:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 3000
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

20:06:48.378 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version: 2.4.0
20:06:48.378 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 77a89fcf8d7fa018
20:06:48.379 [main] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1674311808378
20:06:48.382 [kafka-producer-network-thread | producer-14] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-14] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
20:06:48.385 [kafka-producer-network-thread | producer-14] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-14] Got error produce response with correlation id 3 on topic-partition test-topic-api-1-replication-2, retrying (9 attempts left). Error: NOT_ENOUGH_REPLICAS
20:06:48.479 [kafka-producer-network-thread | producer-13] INFO  org.apache.kafka.clients.Metadata - [Producer clientId=producer-13] Cluster ID: xoB0MzT2T5GsMqi_JhiZ9g
20:06:51.388 [kafka-producer-network-thread | producer-14] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-14] Got error produce response with correlation id 4 on topic-partition test-topic-api-1-replication-2, retrying (8 attempts left). Error: NOT_ENOUGH_REPLICAS
20:06:54.393 [kafka-producer-network-thread | producer-14] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-14] Got error produce response with correlation id 5 on topic-partition test-topic-api-1-replication-2, retrying (7 attempts left). Error: NOT_ENOUGH_REPLICAS
20:06:57.399 [kafka-producer-network-thread | producer-14] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-14] Got error produce response with correlation id 6 on topic-partition test-topic-api-1-replication-2, retrying (6 attempts left). Error: NOT_ENOUGH_REPLICAS
20:07:00.401 [kafka-producer-network-thread | producer-14] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-14] Got error produce response with correlation id 7 on topic-partition test-topic-api-1-replication-2, retrying (5 attempts left). Error: NOT_ENOUGH_REPLICAS
20:07:03.406 [kafka-producer-network-thread | producer-14] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-14] Got error produce response with correlation id 8 on topic-partition test-topic-api-1-replication-2, retrying (4 attempts left). Error: NOT_ENOUGH_REPLICAS
20:07:06.410 [kafka-producer-network-thread | producer-14] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-14] Got error produce response with correlation id 9 on topic-partition test-topic-api-1-replication-2, retrying (3 attempts left). Error: NOT_ENOUGH_REPLICAS
20:07:09.417 [kafka-producer-network-thread | producer-14] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-14] Got error produce response with correlation id 10 on topic-partition test-topic-api-1-replication-2, retrying (2 attempts left). Error: NOT_ENOUGH_REPLICAS
20:07:12.423 [kafka-producer-network-thread | producer-14] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-14] Got error produce response with correlation id 11 on topic-partition test-topic-api-1-replication-2, retrying (1 attempts left). Error: NOT_ENOUGH_REPLICAS
20:07:15.429 [kafka-producer-network-thread | producer-14] WARN  o.a.k.c.producer.internals.Sender - [Producer clientId=producer-14] Got error produce response with correlation id 12 on topic-partition test-topic-api-1-replication-2, retrying (0 attempts left). Error: NOT_ENOUGH_REPLICAS
20:07:18.434 [main] INFO  o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-13] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
